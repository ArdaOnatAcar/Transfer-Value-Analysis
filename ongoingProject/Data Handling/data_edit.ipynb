{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize player names\n",
    "def normalize_player_name(name):\n",
    "    if not isinstance(name, str):\n",
    "        return name\n",
    "    \n",
    "    # Replace common special characters\n",
    "    replacements = {\n",
    "        'á': 'a', 'à': 'a', 'â': 'a', 'ä': 'a', 'ã': 'a', 'å': 'a',\n",
    "        'é': 'e', 'è': 'e', 'ê': 'e', 'ë': 'e',\n",
    "        'í': 'i', 'ì': 'i', 'î': 'i', 'ï': 'i',\n",
    "        'ó': 'o', 'ò': 'o', 'ô': 'o', 'ö': 'o', 'õ': 'o', 'ø': 'o',\n",
    "        'ú': 'u', 'ù': 'u', 'û': 'u', 'ü': 'u',\n",
    "        'ý': 'y', 'ÿ': 'y',\n",
    "        'ñ': 'n', 'ç': 'c', 'ß': 'ss', 'ð': 'd', 'þ': 'th',\n",
    "        'Á': 'A', 'À': 'A', 'Â': 'A', 'Ä': 'A', 'Ã': 'A', 'Å': 'A',\n",
    "        'É': 'E', 'È': 'E', 'Ê': 'E', 'Ë': 'E',\n",
    "        'Í': 'I', 'Ì': 'I', 'Î': 'I', 'Ï': 'I',\n",
    "        'Ó': 'O', 'Ò': 'O', 'Ô': 'O', 'Ö': 'O', 'Õ': 'O', 'Ø': 'O',\n",
    "        'Ú': 'U', 'Ù': 'U', 'Û': 'U', 'Ü': 'U',\n",
    "        'Ý': 'Y', 'Ÿ': 'Y',\n",
    "        'Ñ': 'N', 'Ç': 'C', 'Ð': 'D', 'Þ': 'Th',\n",
    "        'Ł': 'L', 'ł': 'l', 'Ś': 'S', 'ś': 's', 'Ź': 'Z', 'ź': 'z', 'Ż': 'Z', 'ż': 'z'\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    \n",
    "    # Normalize to ASCII form using unicodedata\n",
    "    name = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Remove any remaining non-alphanumeric characters except spaces\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)\n",
    "    \n",
    "    # Standardize whitespace\n",
    "    name = ' '.join(name.split())\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the combined data for 2021 and 2020\n",
    "df_2021 = pd.read_excel('../Datas/combined_2021_data.xlsx')\n",
    "df_2020 = pd.read_excel('../Datas/combined_2020_data.xlsx')\n",
    "df_fbref = pd.read_excel('../Datas/FBREF_20_21.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge 2020 and 2021 datas into a single data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common players between 2021 and 2020 datasets: 2336\n",
      "5 players have different positions between 2021 and 2020\n",
      "After processing: 2336 players in transfermarkt data\n",
      "Transfermarkt dataset created with 2336 players and 6 columns\n"
     ]
    }
   ],
   "source": [
    "# Find common players between the datasets\n",
    "common_players = set(df_2021['Player']) & set(df_2020['Player'])\n",
    "print(f\"Number of common players between 2021 and 2020 datasets: {len(common_players)}\")\n",
    "\n",
    "# Filter datasets to only include common players\n",
    "df_2021_filtered = df_2021[df_2021['Player'].isin(common_players)]\n",
    "df_2020_filtered = df_2020[df_2020['Player'].isin(common_players)]\n",
    "\n",
    "# Check for position changes (for informational purposes only)\n",
    "position_changes = 0\n",
    "for player in common_players:\n",
    "    pos_2021 = df_2021_filtered.loc[df_2021_filtered['Player'] == player, 'Position'].values[0]\n",
    "    pos_2020 = df_2020_filtered.loc[df_2020_filtered['Player'] == player, 'Position'].values[0]\n",
    "    if pos_2021 != pos_2020:\n",
    "        position_changes += 1\n",
    "print(f\"{position_changes} players have different positions between 2021 and 2020\")\n",
    "\n",
    "# Create a new DataFrame with only the columns we want in the exact order requested\n",
    "transfermarkt_data = pd.DataFrame()\n",
    "transfermarkt_data['Player'] = list(common_players)\n",
    "transfermarkt_data = transfermarkt_data.merge(df_2020_filtered[['Player', 'Age']], on='Player', how='left')\n",
    "transfermarkt_data = transfermarkt_data.merge(df_2020_filtered[['Player', 'Value (2020)']], on='Player', how='left')\n",
    "transfermarkt_data = transfermarkt_data.merge(df_2021_filtered[['Player', 'Value (2021)']], on='Player', how='left')\n",
    "transfermarkt_data = transfermarkt_data.merge(df_2021_filtered[['Player', 'League']], on='Player', how='left')\n",
    "transfermarkt_data = transfermarkt_data.merge(df_2021_filtered[['Player', 'Position']], on='Player', how='left')\n",
    "\n",
    "# Remove duplicates if any\n",
    "transfermarkt_data = transfermarkt_data.drop_duplicates(subset=['Player'], keep='first')\n",
    "print(f\"After processing: {len(transfermarkt_data)} players in transfermarkt data\")\n",
    "\n",
    "# Save the transfermarkt dataset\n",
    "transfermarkt_data.to_excel('../Datas/transfermarkt_scrape.xlsx', index=False)\n",
    "print(f\"Transfermarkt dataset created with {len(transfermarkt_data)} players and {len(transfermarkt_data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge transfermarkt_scrape.xlsx and FBREF_20_21.xlsx into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing player names to handle special characters...\n",
      "Number of common players between transfermarkt and FBREF datasets: 1768\n",
      "Found 2 duplicate player entries in the final dataset.\n",
      "Duplicate players:\n",
      "['Hernani']\n",
      "Final dataset contains 1768 players and 141 columns\n",
      "Final dataset saved as 'final_dataset.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "transfermarkt_data = pd.read_excel('../Datas/transfermarkt_scrape.xlsx')\n",
    "fbref_data = pd.read_excel('../Datas/FBREF_20_21.xlsx')\n",
    "\n",
    "# Normalize player names in all datasets\n",
    "print(\"Normalizing player names to handle special characters...\")\n",
    "transfermarkt_data['Player'] = transfermarkt_data['Player'].apply(normalize_player_name)\n",
    "fbref_data['Player'] = fbref_data['Player'].apply(normalize_player_name)\n",
    "\n",
    "\n",
    "# Make sure Player column in fbref_data is consistently named\n",
    "if 'player' in fbref_data.columns and 'Player' not in fbref_data.columns:\n",
    "    fbref_data = fbref_data.rename(columns={'player': 'Player'})\n",
    "\n",
    "# Find common players between the datasets\n",
    "common_players = set(transfermarkt_data['Player']) & set(fbref_data['Player'])\n",
    "print(f\"Number of common players between transfermarkt and FBREF datasets: {len(common_players)}\")\n",
    "\n",
    "# Filter datasets to only include common players\n",
    "transfermarkt_filtered = transfermarkt_data[transfermarkt_data['Player'].isin(common_players)]\n",
    "fbref_filtered = fbref_data[fbref_data['Player'].isin(common_players)]\n",
    "\n",
    "# Merge the datasets on Player column\n",
    "# Using left join to keep the order of players from transfermarkt_data\n",
    "final_dataset = pd.merge(transfermarkt_filtered, fbref_filtered, on='Player', how='inner')\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_players = final_dataset[final_dataset.duplicated(subset=['Player'], keep=False)]\n",
    "if len(duplicate_players) > 0:\n",
    "    print(f\"Found {len(duplicate_players)} duplicate player entries in the final dataset.\")\n",
    "    print(\"Duplicate players:\")\n",
    "    print(duplicate_players['Player'].unique())\n",
    "    \n",
    "    # Remove duplicates if any exist\n",
    "    final_dataset = final_dataset.drop_duplicates(subset=['Player'], keep='first')\n",
    "\n",
    "print(f\"Final dataset contains {len(final_dataset)} players and {len(final_dataset.columns)} columns\")\n",
    "\n",
    "# Save the final dataset\n",
    "final_dataset.to_excel('../Datas/final_dataset.xlsx', index=False)\n",
    "print(\"Final dataset saved as 'final_dataset.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates: 1768 unique players remain\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate players before removing\n",
    "duplicate_players = final_dataset[final_dataset.duplicated(subset=['Player'], keep=False)]\n",
    "if len(duplicate_players) > 0:\n",
    "    print(f\"Found {len(duplicate_players)} duplicate player entries.\")\n",
    "    print(\"Duplicate players:\")\n",
    "    print(duplicate_players['Player'].unique())\n",
    "\n",
    "# Remove duplicate rows based on 'Player' column, keeping the first occurrence\n",
    "final_dataset = final_dataset.drop_duplicates(subset=['Player'], keep='first')\n",
    "print(f\"After removing duplicates: {len(final_dataset)} unique players remain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Goalkeepers because the stats do not suit goalkeepers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing Goalkeepers: 1614 players remain\n"
     ]
    }
   ],
   "source": [
    "# Remove players those have the Position attribute set to Goalkeeper\n",
    "final_dataset = final_dataset[final_dataset['Position'] != 'Goalkeeper']\n",
    "print(f\"After removing Goalkeepers: {len(final_dataset)} players remain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group players into 3 categories: Defenders, Midfielders, Attackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Players into positions\n",
    "Defenders = ['Left-Back', 'Right-Back', 'Centre-Back']\n",
    "Midfielders = ['Defensive Midfield', 'Central Midfield', 'Attacking Midfield','Right Midfield', 'Left Midfield']\n",
    "Forwards = ['Left Winger', 'Right Winger', 'Centre-Forward', 'Second Striker']\n",
    "\n",
    "# Create a new column for Player Type\n",
    "final_dataset['Category'] = 'Unknown'\n",
    "final_dataset.loc[final_dataset['Position'].isin(Defenders), 'Category'] = 'Defender'\n",
    "final_dataset.loc[final_dataset['Position'].isin(Midfielders), 'Category'] = 'Midfielder'\n",
    "final_dataset.loc[final_dataset['Position'].isin(Forwards), 'Category'] = 'Forward'\n",
    "\n",
    "# Get all column names\n",
    "all_columns = final_dataset.columns.tolist()\n",
    "\n",
    "# Remove 'Value Difference' from its current position\n",
    "all_columns.remove('Category')\n",
    "\n",
    "# Determine the first three columns (keep them in their original order)\n",
    "first_three_columns = all_columns[:6]\n",
    "\n",
    "# Insert 'Value Difference' as the 4th column\n",
    "new_column_order = first_three_columns + ['Category'] + all_columns[6:]\n",
    "\n",
    "# Reindex the DataFrame with the new column order\n",
    "final_dataset = final_dataset[new_column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add value difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for the difference in value between 2020 and 2021 that is Value (2021) - Value (2020) \n",
    "final_dataset['Value Difference'] = final_dataset['Value (2021)'] - final_dataset['Value (2020)']\n",
    "# Get all column names\n",
    "all_columns = final_dataset.columns.tolist()\n",
    "\n",
    "# Remove 'Value Difference' from its current position\n",
    "all_columns.remove('Value Difference')\n",
    "\n",
    "# Determine the first three columns (keep them in their original order)\n",
    "first_three_columns = all_columns[:7]\n",
    "\n",
    "# Insert 'Value Difference' as the 4th column\n",
    "new_column_order = first_three_columns + ['Value Difference'] + all_columns[7:]\n",
    "\n",
    "# Reindex the DataFrame with the new column order\n",
    "final_dataset = final_dataset[new_column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add value difference for players who have nonzero values at 2020 and 2021 as percentage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove players with 0 value in Value (2020)\n",
    "final_dataset = final_dataset[final_dataset['Value (2020)'] != 0]\n",
    "# Remove players with 0 value in Value (2021)\n",
    "final_dataset = final_dataset[final_dataset['Value (2021)'] != 0]\n",
    "\n",
    "# Add a new column for the difference in value between 2020 and 2021 that is Value (2021) - Value (2020) \n",
    "final_dataset['Value Difference (%)'] = (final_dataset['Value (2021)'] - final_dataset['Value (2020)'])/final_dataset['Value (2020)'] * 100\n",
    "# Get all column names\n",
    "all_columns = final_dataset.columns.tolist()\n",
    "\n",
    "# Remove 'Value Difference' from its current position\n",
    "all_columns.remove('Value Difference (%)')\n",
    "\n",
    "# Determine the first three columns (keep them in their original order)\n",
    "first_three_columns = all_columns[:8]\n",
    "\n",
    "# Insert 'Value Difference' as the 4th column\n",
    "new_column_order = first_three_columns + ['Value Difference (%)'] + all_columns[8:]\n",
    "\n",
    "# Reindex the DataFrame with the new column order\n",
    "final_dataset = final_dataset[new_column_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_excel('../Datas/final_dataset.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset created with 1608 players and 144 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"Combined dataset created with {len(final_dataset)} players and {len(final_dataset.columns)} columns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
